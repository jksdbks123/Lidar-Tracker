{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Open3D INFO] Resetting default logger to print to terminal.\n"
     ]
    }
   ],
   "source": [
    "from MOT import MOT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from BfTableGenerator import RansacCollector\n",
    "from BfTableGenerator import TDmapLoader\n",
    "from tqdm import tqdm\n",
    "from Utils import *\n",
    "from DDBSCAN import Raster_DBSCAN\n",
    "import open3d as op3\n",
    "# op3.visualization.webrtc_server.enable_webrtc()\n",
    "from open3d.web_visualizer import draw\n",
    "from VisulizerTools import *\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from scipy.stats import multivariate_normal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcd_colored(Td_map,Labeling_map,Foreground_map):\n",
    "    \n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    Zs = []\n",
    "    Labels = []\n",
    "    for i in range(Td_map.shape[0]):\n",
    "        longitudes = theta[i]*np.pi / 180\n",
    "        latitudes = azimuths * np.pi / 180 \n",
    "        hypotenuses = Td_map[i] * np.cos(longitudes)\n",
    "        X = hypotenuses * np.sin(latitudes)\n",
    "        Y = hypotenuses * np.cos(latitudes)\n",
    "        Z = Td_map[i] * np.sin(longitudes)\n",
    "        Valid_ind = Td_map[i] != 0\n",
    "        Xs.append(X[Valid_ind])\n",
    "        Ys.append(Y[Valid_ind])\n",
    "        Zs.append(Z[Valid_ind])\n",
    "        Labels.append(Labeling_map[i][Valid_ind])\n",
    "\n",
    "    Xs = np.concatenate(Xs)\n",
    "    Ys = np.concatenate(Ys)\n",
    "    Zs = np.concatenate(Zs)\n",
    "    Labels = np.concatenate(Labels)\n",
    "    XYZ = np.concatenate([Xs.reshape(-1,1),Ys.reshape(-1,1),Zs.reshape(-1,1)],axis = 1)\n",
    "    Colors = np.full((len(Labels),3),np.array([[153,153,153]])/256)\n",
    "    unique_label = np.unique(Labels)\n",
    "    for l in unique_label[1:]:\n",
    "        Colors[Labels == l] = color_map[l%len(color_map)]\n",
    "\n",
    "    pcd = op3.geometry.PointCloud()\n",
    "    pcd.points = op3.utility.Vector3dVector(XYZ)\n",
    "    pcd.colors = op3.utility.Vector3dVector(Colors)\n",
    "    return pcd    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affinity_mat_jpd_TR(state,state_,P_,mea):\n",
    "    State_affinity = np.zeros((state_.shape[1],state_.shape[0],mea.shape[0]))\n",
    "    for i,s_ in enumerate(state_):\n",
    "         # includes the pred states for two reprs \n",
    "         # s_: 2 x 6 x 1\n",
    "        state_cur = state[i].copy().reshape(2,-1)[:,:2]\n",
    "        state_pred = s_.copy().reshape(2,-1)[:,:2]\n",
    "        \n",
    "         # cov_tr : 2 x 6 x 6 \n",
    "        cov_tr = P_[i][:,:2,:2]\n",
    "        var_tr = [multivariate_normal(mean=state_pred[k], cov=cov_tr[k]) for k in range(state_cur.shape[0])]\n",
    "        for j,m in enumerate(mea):\n",
    "            mea_next = m.copy().reshape(2,-1)\n",
    "            for k in range(s_.shape[0]):\n",
    "                dis_error = np.sqrt(np.sum((state_pred[k] - mea_next[k])**2))\n",
    "                if dis_error < 5:\n",
    "                    jp = var_tr[k].pdf(mea_next[k])\n",
    "                    State_affinity[k,i,j] = jp\n",
    "    \n",
    "    return np.max(State_affinity,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representative_point(rows,cols,Td_map): \n",
    "    td_freq_map = Td_map\n",
    "    longitudes = theta[rows]*np.pi / 180\n",
    "    latitudes = azimuths[cols] * np.pi / 180 \n",
    "    hypotenuses = td_freq_map[rows,cols] * np.cos(longitudes)\n",
    "    X = hypotenuses * np.sin(latitudes)\n",
    "    Y = hypotenuses * np.cos(latitudes)\n",
    "    Z = td_freq_map[rows,cols] * np.sin(longitudes)\n",
    "    \n",
    "    return np.array([X,Y]).reshape(-1,2,1) # n_repr x xy_dim x 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Lidar-Tracker\\\\Lidar-Tracker'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pcap...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [01:52<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Threshold Map\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(r'/Users/czhui960/Documents/Lidar/RawLidarData/FrameSamplingTest')\n",
    "# thred_map = np.load(r'Output File/thred_map_1200.npy')\n",
    "collector = RansacCollector(pcap_path=r'../RawLidarData/McCarranEvans_Train/Train.pcap',output_file_path='../RawLidarData/McCarranEvans_Train',update_frame_num=2000)\n",
    "collector.gen_tdmap()\n",
    "collector.gen_thredmap(d = 1,thred_s = 0.2,N = 20,delta_thred = 1e-3,step = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Raster_DBSCAN(window_size=(5,13),eps = 1.7, min_samples= 17,Td_map_szie=collector.thred_map.shape)   \n",
    "for frame in range(700):\n",
    "    Td_map = collector.aggregated_map[frame]\n",
    "    Foreground_map = (Td_map < collector.thred_map)&(Td_map != 0)\n",
    "    Labeling_map = db.fit_predict(Td_map= Td_map,Foreground_map=Foreground_map)\n",
    "    Background_map = (Td_map >= collector.thred_map)&(Td_map != 0)\n",
    "    thred_merge = 80\n",
    "    unique_label = np.unique(Labeling_map)\n",
    "    #Only Background contains \n",
    "    if -1 in unique_label:\n",
    "        unique_label = unique_label[1:]\n",
    "    occlusion_indicator = -np.ones((len(azimuths))).astype('int')\n",
    "    rowses = []\n",
    "    colses = []\n",
    "    for l in unique_label:\n",
    "        rows,cols = np.where(Labeling_map == l)\n",
    "        occlusion_indicator[cols] = l\n",
    "        rowses.append(rows)\n",
    "        colses.append(cols)\n",
    "    TSAv = occlusion_indicator != -1\n",
    "    counts,appears = count(TSAv)\n",
    "    Merge_cobs = []\n",
    "    ind_pairs = [(i,i+1) for i in range(len(counts) - 1)]\n",
    "    ind_pairs += [(-1,0)]\n",
    "    for pair in ind_pairs:\n",
    "        col_right = appears[pair[0]] + counts[pair[0]] - 1\n",
    "        col_left = appears[pair[1]]\n",
    "        is_normal = col_left >= col_right\n",
    "        if is_normal&((col_left - col_right) > thred_merge):\n",
    "            continue\n",
    "        bounder_right_label = occlusion_indicator[col_right]\n",
    "        bounder_left_label = occlusion_indicator[col_left]\n",
    "        # right-bound on left ---- left-boundon right\n",
    "        label_ind_right= np.where(unique_label == bounder_right_label)[0][0]\n",
    "        rows_right = rowses[label_ind_right][colses[label_ind_right] == col_right]\n",
    "        label_ind_left = np.where(unique_label == bounder_left_label)[0][0]\n",
    "        rows_left = rowses[label_ind_left][colses[label_ind_left] == col_left]\n",
    "        rows_2bounds = np.concatenate([rows_left,rows_right])\n",
    "        high,low = rows_2bounds.max(),rows_2bounds.min()\n",
    "        if is_normal:\n",
    "            interval_map = Td_map[low:high+1,col_right:col_left+1][Background_map[low:high+1,col_right:col_left+1]]\n",
    "        else:\n",
    "            if (len(azimuths) - col_right) + col_left > thred_merge:\n",
    "                continue\n",
    "            else: \n",
    "                interval_map_right = Td_map[low:high+1,col_right:len(azimuths)][Background_map[low:high+1,col_right:len(azimuths)]]\n",
    "                interval_map_left = Td_map[low:high+1,:col_left + 1][Background_map[low:high+1,:col_left + 1]]\n",
    "                interval_map = np.concatenate([interval_map_left,interval_map_right])\n",
    "        if len(interval_map) == 0 :\n",
    "            continue\n",
    "\n",
    "        min_dis_int = interval_map.min()\n",
    "        min_dis_right = Td_map[rows_right,col_right].min()\n",
    "        min_dis_left = Td_map[rows_left,col_left].min()\n",
    "        if (min_dis_int  < min_dis_right)&(min_dis_int < min_dis_left)&(np.abs(min_dis_right - min_dis_left) < 1.2):\n",
    "            Merge_cobs.append([label_ind_right,label_ind_left])\n",
    "\n",
    "    for cob in Merge_cobs:\n",
    "        for i in range(1,len(cob)):\n",
    "            Labeling_map[Labeling_map == cob[i]] = cob[0]\n",
    "            unique_label[unique_label == cob[i]] = cob[0]\n",
    "\n",
    "    new_uni_labels = np.unique(unique_label)\n",
    "    xy_set = []\n",
    "    for label in new_uni_labels:\n",
    "        rows,cols = np.where(Labeling_map == label)\n",
    "        sort_ind = np.argsort(cols)\n",
    "        refer_cols = cols[sort_ind[[0,-1]]]\n",
    "        # this is being said, the first place is for less azimuth id \n",
    "        refer_rows = rows[sort_ind[[0,-1]]]\n",
    "        if np.abs(refer_cols[0] - refer_cols[1]) >= 900:\n",
    "            cols[cols <= 900] += 1800\n",
    "            sort_ind = np.argsort(cols)\n",
    "            refer_cols = cols[sort_ind[[0,-1]]]\n",
    "            refer_cols[refer_cols >= 1800] -= 1800\n",
    "            refer_rows = rows[sort_ind[[0,-1]]]\n",
    "        xy_set.append(get_representative_point(refer_rows,refer_cols,Td_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Raster_DBSCAN(window_size=(5,13),eps = 1.7, min_samples= 17,Td_map_szie=collector.thred_map.shape)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a03570603e409cb6c070143db0b59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_9')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Td_map = collector.aggregated_map[1000]\n",
    "Foreground_map = (Td_map < collector.thred_map)&(Td_map != 0)\n",
    "Labeling_map = db.fit_predict(Td_map= Td_map,Foreground_map=Foreground_map)\n",
    "Background_map = (Td_map >= collector.thred_map)&(Td_map != 0)\n",
    "\n",
    "\n",
    "thred_merge = 30\n",
    "unique_label = np.unique(Labeling_map)\n",
    "#Only Background contains \n",
    "if -1 in unique_label:\n",
    "    unique_label = unique_label[1:]\n",
    "occlusion_indicator = -np.ones((len(azimuths))).astype('int')\n",
    "rowses = []\n",
    "colses = []\n",
    "for l in unique_label:\n",
    "    rows,cols = np.where(Labeling_map == l)\n",
    "    occlusion_indicator[cols] = l\n",
    "    rowses.append(rows)\n",
    "    colses.append(cols)\n",
    "TSAv = occlusion_indicator != -1\n",
    "counts,appears = count(TSAv)\n",
    "Merge_cobs = []\n",
    "ind_pairs = [(i,i+1) for i in range(len(counts) - 1)]\n",
    "ind_pairs += [(-1,0)]\n",
    "for pair in ind_pairs:\n",
    "    col_right = appears[pair[0]] + counts[pair[0]] - 1\n",
    "    col_left = appears[pair[1]]\n",
    "    is_normal = col_left >= col_right\n",
    "    if is_normal&((col_left - col_right) > thred_merge):\n",
    "        continue\n",
    "    bounder_right_label = occlusion_indicator[col_right]\n",
    "    bounder_left_label = occlusion_indicator[col_left]\n",
    "    # right-bound on left ---- left-bound on right\n",
    "    label_ind_right= np.where(unique_label == bounder_right_label)[0][0]\n",
    "    rows_right = rowses[label_ind_right][colses[label_ind_right] == col_right]\n",
    "    label_ind_left = np.where(unique_label == bounder_left_label)[0][0]\n",
    "    rows_left = rowses[label_ind_left][colses[label_ind_left] == col_left]\n",
    "    rows_2bounds = np.concatenate([rows_left,rows_right])\n",
    "    high,low = rows_2bounds.max(),rows_2bounds.min()\n",
    "    if is_normal:\n",
    "        interval_map = Td_map[low:high+1,col_right:col_left+1][Background_map[low:high+1,col_right:col_left+1]]\n",
    "    else:\n",
    "        if (len(azimuths) - col_right) + col_left > thred_merge:\n",
    "            continue\n",
    "        else: \n",
    "            interval_map_right = Td_map[low:high+1,col_right:len(azimuths)][Background_map[low:high+1,col_right:len(azimuths)]]\n",
    "            interval_map_left = Td_map[low:high+1,:col_left + 1][Background_map[low:high+1,:col_left + 1]]\n",
    "            interval_map = np.concatenate([interval_map_left,interval_map_right])\n",
    "    if len(interval_map) == 0 :\n",
    "        continue\n",
    "\n",
    "    min_dis_int = interval_map.min()\n",
    "    min_dis_right = Td_map[rows_right,col_right].min()\n",
    "    min_dis_left = Td_map[rows_left,col_left].min()\n",
    "    if (min_dis_int  < min_dis_right)&(min_dis_int < min_dis_left)&(np.abs(min_dis_right - min_dis_left) < 2.5):\n",
    "        Merge_cobs.append([label_ind_right,label_ind_left])\n",
    "\n",
    "for cob in Merge_cobs:\n",
    "    for i in range(1,len(cob)):\n",
    "        Labeling_map[Labeling_map == cob[i]] = cob[0]\n",
    "        unique_label[unique_label == cob[i]] = cob[0]\n",
    "\n",
    "new_uni_labels = np.unique(unique_label)\n",
    "xy_set = []\n",
    "for label in new_uni_labels:\n",
    "    rows,cols = np.where(Labeling_map == label)\n",
    "    sort_ind = np.argsort(cols)\n",
    "    refer_cols = cols[sort_ind[[0,-1]]]\n",
    "    # this is being said, the first place is for less azimuth id \n",
    "    refer_rows = rows[sort_ind[[0,-1]]]\n",
    "    if np.abs(refer_cols[0] - refer_cols[1]) >= 900:\n",
    "        cols[cols <= 900] += 1800\n",
    "        sort_ind = np.argsort(cols)\n",
    "        refer_cols = cols[sort_ind[[0,-1]]]\n",
    "        refer_cols[refer_cols >= 1800] -= 1800\n",
    "        refer_rows = rows[sort_ind[[0,-1]]]\n",
    "    xy_set.append(get_representative_point(refer_rows,refer_cols,Td_map))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pcd = get_pcd_colored(Td_map,Labeling_map,Foreground_map)\n",
    "draw(pcd, height = 1000,width = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.116880781646981"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = np.array([\n",
    "    [1,0.2],\n",
    "    [0.3,2]\n",
    "])\n",
    "VI = inv(V)\n",
    "distance.mahalanobis([1.1,0], [0,0], VI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance.mahalanobis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42302c28e5085b919aea458e627b8255e1e792dac20b85945e8189f2b9f9260e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
