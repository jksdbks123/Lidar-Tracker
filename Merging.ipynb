{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MOT import MOT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from BfTableGenerator import RansacCollector\n",
    "from BfTableGenerator import TDmapLoader\n",
    "from tqdm import tqdm\n",
    "# from open3d import JVisualizer \n",
    "from Utils import *\n",
    "from DDBSCAN import Raster_DBSCAN\n",
    "import open3d as op3\n",
    "# op3.visualization.webrtc_server.enable_webrtc()\n",
    "# from open3d.web_visualizer import draw\n",
    "from VisulizerTools import *\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from scipy.stats import multivariate_normal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affinity_mat_jpd_TR(state,state_,P_,mea):\n",
    "    State_affinity = np.zeros((state_.shape[1],state_.shape[0],mea.shape[0]))\n",
    "    for i,s_ in enumerate(state_):\n",
    "         # includes the pred states for two reprs \n",
    "         # s_: 2 x 6 x 1\n",
    "        state_cur = state[i].copy().reshape(2,-1)[:,:2]\n",
    "        state_pred = s_.copy().reshape(2,-1)[:,:2]\n",
    "        \n",
    "         # cov_tr : 2 x 6 x 6 \n",
    "        cov_tr = P_[i][:,:2,:2]\n",
    "        var_tr = [multivariate_normal(mean=state_pred[k], cov=cov_tr[k]) for k in range(state_cur.shape[0])]\n",
    "        for j,m in enumerate(mea):\n",
    "            mea_next = m.copy().reshape(2,-1)\n",
    "            for k in range(s_.shape[0]):\n",
    "                dis_error = np.sqrt(np.sum((state_pred[k] - mea_next[k])**2))\n",
    "                if dis_error < 5:\n",
    "                    jp = var_tr[k].pdf(mea_next[k])\n",
    "                    State_affinity[k,i,j] = jp\n",
    "    \n",
    "    return np.max(State_affinity,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_xy_interval_merging_TR(Labeling_map,Td_map,Background_map):\n",
    "        \n",
    "    unique_label = np.unique(Labeling_map)\n",
    "    if len(unique_label) == 1:\n",
    "        return np.array([]),[],Labeling_map\n",
    "    if -1 in unique_label:\n",
    "        unique_label = unique_label[1:]\n",
    "    \n",
    "    boundary_cols = []\n",
    "    boundary_rows = []\n",
    "    for l in unique_label:\n",
    "        rows,cols = np.where(Labeling_map == l)\n",
    "        sorted_cols_ind = np.argsort(cols)\n",
    "        sorted_cols = cols[sorted_cols_ind]\n",
    "        sorted_rows = rows[sorted_cols_ind]\n",
    "        left_col,right_col = sorted_cols[0],sorted_cols[-1]\n",
    "        \n",
    "        if (right_col - left_col) >  900:\n",
    "            left_col += 1800 \n",
    "        boundary_cols.append([left_col,right_col])\n",
    "        boundary_rows.append([rows[sorted_cols_ind[0]],rows[sorted_cols_ind[-1]]])\n",
    "\n",
    "    boundary_cols,boundary_rows = np.array(boundary_cols),np.array(boundary_rows)\n",
    "    \n",
    "    sorted_label = np.argsort(boundary_cols[:,0])\n",
    "\n",
    "    adjacent_label_pairs = []\n",
    "    for sl in range(len(sorted_label) - 1):\n",
    "        if boundary_cols[sorted_label[sl],1] < boundary_cols[sorted_label[sl+1],0]:\n",
    "            adjacent_label_pairs.append([sorted_label[sl],sorted_label[sl+1]])\n",
    "            \n",
    "    if boundary_cols[sorted_label[-1],1] > 1800:\n",
    "        if (boundary_cols[sorted_label[-1],1] - 1800) < boundary_cols[sorted_label[0],0]:\n",
    "            adjacent_label_pairs.append([sorted_label[-1],sorted_label[0]])\n",
    "    else:\n",
    "        if boundary_cols[sorted_label[-1],1] < boundary_cols[sorted_label[0],0]:\n",
    "            adjacent_label_pairs.append([sorted_label[-1],sorted_label[0]])\n",
    "    Merge_cobs = []\n",
    "    for adjacent in adjacent_label_pairs:\n",
    "        pair_a,pair_b = adjacent[0],adjacent[1]\n",
    "        interval_left_col,interval_right_col = boundary_cols[pair_a][1],boundary_cols[pair_b][0]\n",
    "        interval_left_row,interval_right_row = boundary_rows[pair_a][1],boundary_rows[pair_b][0]\n",
    "    #     print(interval_left_col,interval_right_col)\n",
    "        if (interval_right_col - interval_left_col) > 80:\n",
    "            continue\n",
    "        high = interval_left_row\n",
    "        low = interval_right_row\n",
    "        if high < low: \n",
    "            high,low = low,high\n",
    "        \n",
    "        interval_map = Td_map[low:high+1,interval_left_col:interval_right_col+1][Background_map[low:high+1,interval_left_col:interval_right_col+1]]\n",
    "        if len(interval_map) == 0 :\n",
    "            continue\n",
    "        min_dis_int = interval_map.min()\n",
    "        min_dis_a = Td_map[Labeling_map == pair_a].min()\n",
    "        min_dis_b = Td_map[Labeling_map == pair_b].min()\n",
    "        if (min_dis_int  < min_dis_a)&(min_dis_int  <min_dis_b)&(np.abs(min_dis_a - min_dis_b) < 1.2):\n",
    "            Merge_cobs.append([pair_a,pair_b])\n",
    "    \n",
    "\n",
    "    for cob in Merge_cobs:\n",
    "        for i in range(1,len(cob)):\n",
    "            Labeling_map[Labeling_map == cob[i]] = cob[0]\n",
    "            unique_label[unique_label == cob[i]] = cob[0]\n",
    "            # Labels[Labels == cob[i]] =cob[0]\n",
    "            \n",
    "    new_uni_labels = np.unique(unique_label)\n",
    "    xy_set = []\n",
    "    for label in new_uni_labels:\n",
    "        rows,cols = np.where(Labeling_map == label)\n",
    "        sort_ind = np.argsort(cols)\n",
    "        refer_cols = cols[sort_ind[[0,-1]]]\n",
    "        refer_rows = rows[sort_ind[[0,-1]]]\n",
    "        if np.abs(refer_cols[0] - refer_cols[1]) > 900:\n",
    "            cols[cols < 900] += 1800\n",
    "            sort_ind = np.argsort(cols)\n",
    "            refer_cols = cols[sort_ind[[0,-1]]]\n",
    "            refer_cols[refer_cols > 1800] -= 1800\n",
    "            refer_rows = rows[sort_ind[[0,-1]]]\n",
    "        xy_set.append(get_representative_point(refer_rows,refer_cols,Td_map))\n",
    "    \n",
    "    return np.array(xy_set),new_uni_labels,Labeling_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representative_point(rows,cols,Td_map): \n",
    "    td_freq_map = Td_map\n",
    "    longitudes = theta[rows]*np.pi / 180\n",
    "    latitudes = azimuths[cols] * np.pi / 180 \n",
    "    hypotenuses = td_freq_map[rows,cols] * np.cos(longitudes)\n",
    "    X = hypotenuses * np.sin(latitudes)\n",
    "    Y = hypotenuses * np.cos(latitudes)\n",
    "    Z = td_freq_map[rows,cols] * np.sin(longitudes)\n",
    "    \n",
    "    return np.array([X,Y]).reshape(-1,2,1) # n_repr x xy_dim x 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:00<01:59, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pcap...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:36<00:00, 20.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Threshold Map\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(r'/Users/czhui960/Documents/Lidar/RawLidarData/FrameSamplingTest')\n",
    "# thred_map = np.load(r'Output File/thred_map_1200.npy')\n",
    "collector = RansacCollector(pcap_path=r'../RawLidarData/Veteran/Veteran.pcap',output_file_path='../MergingResult/',update_frame_num=2000)\n",
    "collector.gen_tdmap()\n",
    "collector.gen_thredmap(d = 1.1,thred_s = 0.2,N = 20,delta_thred = 1e-3,step = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Raster_DBSCAN(window_size=(5,13),eps = 1.7, min_samples= 17,Td_map_szie=collector.thred_map.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1487/2000 [00:59<00:32, 15.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1484\n",
      "1485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:27<00:00, 22.92it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(range(2000)):\n",
    "    Td_map = collector.aggregated_map[f]\n",
    "    Foreground_map = (Td_map < collector.thred_map)&(Td_map != 0)\n",
    "    Labeling_map = db.fit_predict(Td_map= Td_map,Foreground_map=Foreground_map)\n",
    "    Background_map = (Td_map >= collector.thred_map)&(Td_map != 0)\n",
    "    for r in range(Labeling_map.shape[0]):\n",
    "        if (Labeling_map[r,0] != -1) & (Labeling_map[r,-1] != -1) & (Labeling_map[r,-1] != Labeling_map[r,0]):\n",
    "            print(f)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "Td_map = collector.aggregated_map[0]\n",
    "Foreground_map = (Td_map < collector.thred_map)&(Td_map != 0)\n",
    "Labeling_map = db.fit_predict(Td_map= Td_map,Foreground_map=Foreground_map)\n",
    "Background_map = (Td_map >= collector.thred_map)&(Td_map != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "mea_init,unique_label_init,Labeling_map = extract_xy_interval_merging_TR(Labeling_map,Td_map,Background_map)\n",
    "n_observed = mea_init.shape[0]\n",
    "n_repr = mea_init.shape[1]\n",
    "n_offset_dim = A.shape[0] - mea_init.shape[2]\n",
    "state_init = np.concatenate([mea_init,np.zeros((n_observed,n_repr,n_offset_dim,1))],axis = 2)\n",
    "# s: n x 2 x 6 x 1\n",
    "P_init = np.full((n_observed,2,P.shape[0],P.shape[1]),P)\n",
    "state_cur,P_cur = state_init,P_init \n",
    "state_cur_,P_cur_ = state_predict(A,Q,state_cur,P_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "Td_map = collector.aggregated_map[1]\n",
    "Foreground_map = (Td_map < collector.thred_map)&(Td_map != 0)\n",
    "Labeling_map = db.fit_predict(Td_map= Td_map,Foreground_map=Foreground_map)\n",
    "Background_map = (Td_map >= collector.thred_map)&(Td_map != 0)\n",
    "mea_next,unique_label_next,Labeling_map = extract_xy_interval_merging_TR(Labeling_map,Td_map,Background_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "State_affinity = get_affinity_mat_jpd_TR(state_cur,state_cur_,P_cur_,mea_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 1)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_init = np.concatenate([mea_next[n_id], np.zeros((A.shape[0] - H.shape[0],1))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "associated_ind_glb,associated_ind_label = linear_assignment_modified(State_affinity)\n",
    "failed_tracked_ind = np.setdiff1d(np.arange(len(mea_next)),associated_ind_glb) \n",
    "new_detection_ind = np.setdiff1d(np.arange(len(unique_label_next)),associated_ind_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "state,P = state_update(A,H,state_cur_[associated_ind_glb],P_cur_[associated_ind_glb],R,mea_next[associated_ind_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[225.01,   0.  ],\n",
       "        [  0.  , 225.01]],\n",
       "\n",
       "       [[225.01,   0.  ],\n",
       "        [  0.  , 225.01]]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_cur_[0][:,:2,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcd_colored(Td_map,Labeling_map,Foreground_map):\n",
    "    \n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    Zs = []\n",
    "    Labels = []\n",
    "    for i in range(Td_map.shape[0]):\n",
    "        longitudes = theta[i]*np.pi / 180\n",
    "        latitudes = azimuths * np.pi / 180 \n",
    "        hypotenuses = Td_map[i] * np.cos(longitudes)\n",
    "        X = hypotenuses * np.sin(latitudes)\n",
    "        Y = hypotenuses * np.cos(latitudes)\n",
    "        Z = Td_map[i] * np.sin(longitudes)\n",
    "        Valid_ind = (Td_map[i] != 0)&(Foreground_map[i])\n",
    "        Xs.append(X[Valid_ind])\n",
    "        Ys.append(Y[Valid_ind])\n",
    "        Zs.append(Z[Valid_ind])\n",
    "        Labels.append(Labeling_map[i][Valid_ind])\n",
    "\n",
    "    Xs = np.concatenate(Xs)\n",
    "    Ys = np.concatenate(Ys)\n",
    "    Zs = np.concatenate(Zs)\n",
    "    Labels = np.concatenate(Labels)\n",
    "    XYZ = np.concatenate([Xs.reshape(-1,1),Ys.reshape(-1,1),Zs.reshape(-1,1)],axis = 1)\n",
    "    Colors = np.full((len(Labels),3),np.array([[153,153,153]])/256)\n",
    "    unique_label = np.unique(Labels)\n",
    "    for l in unique_label[1:]:\n",
    "        Colors[Labels == l] = color_map[l%len(color_map)]\n",
    "\n",
    "    pcd = op3.geometry.PointCloud()\n",
    "    pcd.points = op3.utility.Vector3dVector(XYZ)\n",
    "    pcd.colors = op3.utility.Vector3dVector(Colors)\n",
    "    return pcd    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = get_pcd_colored_specified(Td_map,Labeling_map,Specified_label = [3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e5f7bb8ccf0c05ceb6f1a2a367df183186574b25661c58bd0281a0958a9efbd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('tracking': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
