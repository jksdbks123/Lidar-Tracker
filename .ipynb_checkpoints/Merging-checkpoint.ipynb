{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[028:588][5684] (stun_port.cc:96): Binding request timed out from 192.168.1.x:58471 (wlp59s0)\n"
     ]
    }
   ],
   "source": [
    "from MOT import MOT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from BfTableGenerator import RansacCollector\n",
    "from BfTableGenerator import TDmapLoader\n",
    "from tqdm import tqdm\n",
    "from Utils import *\n",
    "from DDBSCAN import Raster_DBSCAN\n",
    "import open3d as op3\n",
    "# op3.visualization.webrtc_server.enable_webrtc()\n",
    "from open3d.web_visualizer import draw\n",
    "from VisulizerTools import *\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from scipy.stats import multivariate_normal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcd_colored(Td_map,Labeling_map,Foreground_map):\n",
    "    \n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    Zs = []\n",
    "    Labels = []\n",
    "    for i in range(Td_map.shape[0]):\n",
    "        longitudes = theta[i]*np.pi / 180\n",
    "        latitudes = azimuths * np.pi / 180 \n",
    "        hypotenuses = Td_map[i] * np.cos(longitudes)\n",
    "        X = hypotenuses * np.sin(latitudes)\n",
    "        Y = hypotenuses * np.cos(latitudes)\n",
    "        Z = Td_map[i] * np.sin(longitudes)\n",
    "        Valid_ind = (Td_map[i] != 0)&(Foreground_map[i])\n",
    "        Xs.append(X[Valid_ind])\n",
    "        Ys.append(Y[Valid_ind])\n",
    "        Zs.append(Z[Valid_ind])\n",
    "        Labels.append(Labeling_map[i][Valid_ind])\n",
    "\n",
    "    Xs = np.concatenate(Xs)\n",
    "    Ys = np.concatenate(Ys)\n",
    "    Zs = np.concatenate(Zs)\n",
    "    Labels = np.concatenate(Labels)\n",
    "    XYZ = np.concatenate([Xs.reshape(-1,1),Ys.reshape(-1,1),Zs.reshape(-1,1)],axis = 1)\n",
    "    Colors = np.full((len(Labels),3),np.array([[153,153,153]])/256)\n",
    "    unique_label = np.unique(Labels)\n",
    "    for l in unique_label[1:]:\n",
    "        Colors[Labels == l] = color_map[l%len(color_map)]\n",
    "\n",
    "    pcd = op3.geometry.PointCloud()\n",
    "    pcd.points = op3.utility.Vector3dVector(XYZ)\n",
    "    pcd.colors = op3.utility.Vector3dVector(Colors)\n",
    "    return pcd    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affinity_mat_jpd_TR(state,state_,P_,mea):\n",
    "    State_affinity = np.zeros((state_.shape[1],state_.shape[0],mea.shape[0]))\n",
    "    for i,s_ in enumerate(state_):\n",
    "         # includes the pred states for two reprs \n",
    "         # s_: 2 x 6 x 1\n",
    "        state_cur = state[i].copy().reshape(2,-1)[:,:2]\n",
    "        state_pred = s_.copy().reshape(2,-1)[:,:2]\n",
    "        \n",
    "         # cov_tr : 2 x 6 x 6 \n",
    "        cov_tr = P_[i][:,:2,:2]\n",
    "        var_tr = [multivariate_normal(mean=state_pred[k], cov=cov_tr[k]) for k in range(state_cur.shape[0])]\n",
    "        for j,m in enumerate(mea):\n",
    "            mea_next = m.copy().reshape(2,-1)\n",
    "            for k in range(s_.shape[0]):\n",
    "                dis_error = np.sqrt(np.sum((state_pred[k] - mea_next[k])**2))\n",
    "                if dis_error < 5:\n",
    "                    jp = var_tr[k].pdf(mea_next[k])\n",
    "                    State_affinity[k,i,j] = jp\n",
    "    \n",
    "    return np.max(State_affinity,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representative_point(rows,cols,Td_map): \n",
    "    td_freq_map = Td_map\n",
    "    longitudes = theta[rows]*np.pi / 180\n",
    "    latitudes = azimuths[cols] * np.pi / 180 \n",
    "    hypotenuses = td_freq_map[rows,cols] * np.cos(longitudes)\n",
    "    X = hypotenuses * np.sin(latitudes)\n",
    "    Y = hypotenuses * np.cos(latitudes)\n",
    "    Z = td_freq_map[rows,cols] * np.sin(longitudes)\n",
    "    \n",
    "    return np.array([X,Y]).reshape(-1,2,1) # n_repr x xy_dim x 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pcap...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2000/2000 [01:17<00:00, 25.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Threshold Map\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(r'/Users/czhui960/Documents/Lidar/RawLidarData/FrameSamplingTest')\n",
    "# thred_map = np.load(r'Output File/thred_map_1200.npy')\n",
    "collector = RansacCollector(pcap_path=r'../RawLidarData/Veteran/Veteran.pcap',output_file_path='../MergingResult/',update_frame_num=2000)\n",
    "collector.gen_tdmap()\n",
    "collector.gen_thredmap(d = 1,thred_s = 0.2,N = 20,delta_thred = 1e-3,step = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Raster_DBSCAN(window_size=(5,13),eps = 1.7, min_samples= 17,Td_map_szie=collector.thred_map.shape)   \n",
    "Td_map = collector.aggregated_map[5]\n",
    "Foreground_map = (Td_map < collector.thred_map)&(Td_map != 0)\n",
    "Labeling_map = db.fit_predict(Td_map= Td_map,Foreground_map=Foreground_map)\n",
    "Background_map = (Td_map >= collector.thred_map)&(Td_map != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = get_pcd_colored(Td_map,Labeling_map,Foreground_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = get_pcd_colored_specified(Td_map,Labeling_map,[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_label = np.unique(Labeling_map)\n",
    "#Only Background contains \n",
    "if -1 in unique_label:\n",
    "    unique_label = unique_label[1:]\n",
    "occlusion_indicator = -np.ones((len(azimuths))).astype('int')\n",
    "rowses = []\n",
    "colses = []\n",
    "for l in unique_label:\n",
    "    rows,cols = np.where(Labeling_map == l)\n",
    "    occlusion_indicator[cols] = l\n",
    "    rowses.append(rows)\n",
    "    colses.append(cols)\n",
    "TSAv = occlusion_indicator != -1\n",
    "counts,appears = count(TSAv)\n",
    "Merge_cobs = []\n",
    "ind_pairs = [(i,i+1) for i in range(len(counts) - 1)]\n",
    "ind_pairs += [(-1,0)]\n",
    "# for pair in ind_pairs:\n",
    "pair = ind_pairs[3]\n",
    "col_right = appears[pair[0]] + counts[pair[0]] - 1\n",
    "col_left = appears[pair[1]]\n",
    "bounder_right_label = occlusion_indicator[col_right]\n",
    "bounder_left_label = occlusion_indicator[col_left]\n",
    "label_ind_right= np.where(unique_label == bounder_right_label)[0][0]\n",
    "rows_right = rowses[label_ind_right][colses[label_ind_right] == col_right]\n",
    "label_ind_left = np.where(unique_label == bounder_left_label)[0][0]\n",
    "rows_left = rowses[label_ind_left][colses[label_ind_left] == col_left]\n",
    "rows_2bounds = np.concatenate([rows_left,rows_right])\n",
    "high,low = rows_2bounds.max(),rows_2bounds.min()\n",
    "interval_map = Td_map[low:high+1,col_right:col_left+1][Background_map[low:high+1,col_right:col_left+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.176,  9.14 ,  9.144,  9.144,  9.144, 25.284,  9.2  ,  9.108,\n",
       "        9.112,  9.116,  9.116, 25.364,  9.188,  9.112,  9.12 ,  9.128,\n",
       "        9.236, 25.748,  9.192,  9.188,  9.188,  9.18 ,  9.184,  9.212,\n",
       "        9.26 ,  9.212,  9.184,  9.18 ,  9.188,  9.204,  9.244])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interval_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interval_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622 1163\n"
     ]
    }
   ],
   "source": [
    "thred_merge = 70\n",
    "unique_label = np.unique(Labeling_map)\n",
    "#Only Background contains \n",
    "if -1 in unique_label:\n",
    "    unique_label = unique_label[1:]\n",
    "occlusion_indicator = -np.ones((len(azimuths))).astype('int')\n",
    "rowses = []\n",
    "colses = []\n",
    "for l in unique_label:\n",
    "    rows,cols = np.where(Labeling_map == l)\n",
    "    occlusion_indicator[cols] = l\n",
    "    rowses.append(rows)\n",
    "    colses.append(cols)\n",
    "TSAv = occlusion_indicator != -1\n",
    "counts,appears = count(TSAv)\n",
    "Merge_cobs = []\n",
    "ind_pairs = [(i,i+1) for i in range(len(counts) - 1)]\n",
    "ind_pairs += [(-1,0)]\n",
    "for pair in ind_pairs:\n",
    "    col_right = appears[pair[0]] + counts[pair[0]] - 1\n",
    "    col_left = appears[pair[1]]\n",
    "    is_normal = col_left >= col_right\n",
    "    if is_normal&((col_left - col_right) > thred_merge):\n",
    "        continue\n",
    "    bounder_right_label = occlusion_indicator[col_right]\n",
    "    bounder_left_label = occlusion_indicator[col_left]\n",
    "    # right-bound on left ---- left-boundon right\n",
    "    label_ind_right= np.where(unique_label == bounder_right_label)[0][0]\n",
    "    rows_right = rowses[label_ind_right][colses[label_ind_right] == col_right]\n",
    "    label_ind_left = np.where(unique_label == bounder_left_label)[0][0]\n",
    "    rows_left = rowses[label_ind_left][colses[label_ind_left] == col_left]\n",
    "    rows_2bounds = np.concatenate([rows_left,rows_right])\n",
    "    high,low = rows_2bounds.max(),rows_2bounds.min()\n",
    "    if is_normal:\n",
    "        interval_map = Td_map[low:high+1,col_right:col_left+1][Background_map[low:high+1,col_right:col_left+1]]\n",
    "    else:\n",
    "        interval_map_right = Td_map[low:high+1,col_right:col_left+1][Background_map[low:high+1,col_right:col_left+1]]\n",
    "        \n",
    "    if len(interval_map) == 0 :\n",
    "        continue\n",
    "    min_dis_int = interval_map.min()\n",
    "    min_dis_right = Td_map[rows_right,col_right].min()\n",
    "    min_dis_left = Td_map[rows_left,col_left].min()\n",
    "    if (min_dis_int  < min_dis_right)&(min_dis_int < min_dis_left)&(np.abs(min_dis_right - min_dis_left) < 1.2):\n",
    "        Merge_cobs.append([label_ind_right,label_ind_left])\n",
    "\n",
    "for cob in Merge_cobs:\n",
    "    for i in range(1,len(cob)):\n",
    "        Labeling_map[Labeling_map == cob[i]] = cob[0]\n",
    "        unique_label[unique_label == cob[i]] = cob[0]\n",
    "\n",
    "new_uni_labels = np.unique(unique_label)\n",
    "xy_set = []\n",
    "for label in new_uni_labels:\n",
    "    rows,cols = np.where(Labeling_map == label)\n",
    "    sort_ind = np.argsort(cols)\n",
    "    refer_cols = cols[sort_ind[[0,-1]]]\n",
    "    # this is being said, the first place is for less azimuth id \n",
    "    refer_rows = rows[sort_ind[[0,-1]]]\n",
    "    if np.abs(refer_cols[0] - refer_cols[1]) >= 900:\n",
    "        cols[cols <= 900] += 1800\n",
    "        sort_ind = np.argsort(cols)\n",
    "        refer_cols = cols[sort_ind[[0,-1]]]\n",
    "        refer_cols[refer_cols >= 1800] -= 1800\n",
    "        refer_rows = rows[sort_ind[[0,-1]]]\n",
    "    xy_set.append(get_representative_point(refer_rows,refer_cols,Td_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3edb609608f4fe3be9a27c94a84d5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_5')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] Window window_5 created.\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/getIceServers\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/call\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/getIceCandidate\n",
      "[Open3D INFO] DataChannelObserver::OnStateChange label: ServerDataChannel, state: open, peerid: 0.39555874169631045\n",
      "[Open3D INFO] DataChannelObserver::OnStateChange label: ClientDataChannel, state: open, peerid: 0.39555874169631045\n",
      "[Open3D INFO] Sending init frames to window_5.\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[743:274][5579] (webrtc_sdp.cc:420): Failed to parse: \"\". Reason: Expect line: candidate:<candidate-str>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] Can't parse received candidate message.\u001b[0;m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[757:120][5684] (stun_port.cc:96): Binding request timed out from 192.168.1.x:58574 (wlp59s0)\n",
      "[771:852][5684] (stun_port.cc:96): Binding request timed out from 192.168.1.x:44718 (wlp59s0)\n"
     ]
    }
   ],
   "source": [
    "draw(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42302c28e5085b919aea458e627b8255e1e792dac20b85945e8189f2b9f9260e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
